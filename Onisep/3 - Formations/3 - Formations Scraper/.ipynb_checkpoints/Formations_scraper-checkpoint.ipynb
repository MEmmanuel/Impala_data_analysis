{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ce script permet de scraper les formations de l'Onisep\n",
    "# Crée un dictionnaire de la forme :\n",
    "#\n",
    "# Nom de la formation :\n",
    "# --> Débouchés professionnels\n",
    "# ----> Débouchés\n",
    "# ----> Exemples de débouchés\n",
    "#\n",
    "# --> Poursuivre mes études\n",
    "# ----> Poursuivre\n",
    "# ----> Exemples de formations poursuivies\n",
    "#\n",
    "# --> Accès au métier \n",
    "# ----> Accès\n",
    "# ----> Exemples de formations requises\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chemins utiles\n",
    "dir_path = '/home/timothee/PycharmProjects/ImpalaPoleEmploi2/Impala/Formations/'\n",
    "# Dossier data\n",
    "data_dir_path = os.path.join(dir_path, '0 - data')\n",
    "# Dossier output\n",
    "output_dir_path = os.path.join(dir_path, '3 - Formation Scraper/output')\n",
    "    \n",
    "# Dossier output contenant les données et les fiches\n",
    "formations_output_path = os.path.join(dir_path, 'formations.json')\n",
    "errors_output_path = os.path.join(dir_path, 'errors.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Liste des liens vers les formations (8095 formations)\n",
    "formations_file_path = os.path.join(data_dir_path, 'Onisep_formation.csv')\n",
    "df = pd.read_csv(formations_file_path, sep=\";\")\n",
    "formations_links = df.iloc[:,[2,3,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fonction qui récupère les onglets \"Accès à la formation\" et \"Poursuivre mes études\" \n",
    "# de la formation en lien et qui crée une fiche html \n",
    "def parse_formation_page(link):\n",
    "    #print('GET '+ link)\n",
    "    \n",
    "    try:\n",
    "        page = request.urlopen(link).read().decode('utf-8')\n",
    "\n",
    "        page = page.replace('€', 'euros')  # because encode/decode error\n",
    "        page = page.replace(u\"\\u2019\", \"'\")  # because encode/decode error\n",
    "        page = page.replace(u\"\\u2026\", \"é\")  # because encode/decode error\n",
    "        page = page.replace(u\"\\u0153\", \"oe\")  # because encode/decode error\n",
    "\n",
    "        page = page.replace('\\n', '')  # remove new line\n",
    "        page = page.replace('  ', '')  # remove big spaces (to be more human readable)\n",
    "        #file = os.path.join(fiches_dir_path, name.replace('/', '-').replace(' ', '_') + '.html')\n",
    "        #with open(file, 'w', encoding='utf8') as f:\n",
    "        #    f.write(page)\n",
    "\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "        formation = {}\n",
    "        # Onglet \"Débouchés professionnels\"\n",
    "        onglet = soup.find(name='div', attrs={'id': 'oni_onglet-1'})\n",
    "        if onglet is not None:\n",
    "            onglet_name = onglet.h2.extract().get_text()\n",
    "            if onglet_name==\"Débouchés professionnels\":\n",
    "                formation[onglet_name] = {}\n",
    "                formation[onglet_name][\"Débouchés\"] = []\n",
    "                formation[onglet_name][\"Exemples de métiers\"] = []\n",
    "                for element in onglet.find_all():\n",
    "                    #print(element)\n",
    "                    if element.name=='p' and element.get_text() not in [\"Exemple(s) de métier(s):\"]:\n",
    "                        formation[onglet_name][\"Débouchés\"].append(element.get_text())\n",
    "                    if element.name=='li':\n",
    "                        formation[onglet_name][\"Exemples de métiers\"].append(element.get_text())\n",
    "                        #print(element)\n",
    "                        \n",
    "        # Onglet \"Accès à la formation\"\n",
    "        onglet = soup.find(name='div', attrs={'id': 'oni_onglet-2'})\n",
    "        if onglet is not None:\n",
    "            onglet_name = onglet.h2.extract().get_text()\n",
    "            if onglet_name==\"Accès à la formation \":\n",
    "                formation[onglet_name]={}\n",
    "                formation[onglet_name][\"Accès\"] = []\n",
    "                formation[onglet_name][\"Exemples de formations requises\"] = []\n",
    "                for element in onglet.find_all():\n",
    "                    #print(element)\n",
    "                    if element.name=='p' and element.get_text() not in [\"Admission\",\"Exemples de formations requises:\"]:\n",
    "                        formation[onglet_name][\"Accès\"].append(element.get_text())\n",
    "                    if element.name=='li' and element.find(name='a')==None:\n",
    "                        formation[onglet_name][\"Accès\"].append(element.get_text())\n",
    "                    if element.name=='li' and element.find(name='a')!=None:\n",
    "                        formation[onglet_name][\"Exemples de formations requises\"].append(element.get_text())\n",
    "\n",
    "                            \n",
    "        # Onglet \"Poursuivre mes études\"\n",
    "        onglet = soup.find(name='div', attrs={'id': 'oni_onglet-3'})\n",
    "        if onglet is not None:\n",
    "            onglet_name = onglet.h2.extract().get_text()\n",
    "            if onglet_name==\"Poursuivre mes études...\":\n",
    "                formation[onglet_name]={}\n",
    "                formation[onglet_name][\"Poursuivre\"] = []\n",
    "                formation[onglet_name][\"Exemples de formations poursuivies\"] = []\n",
    "                for element in onglet.find_all():\n",
    "                    if element.name=='li':\n",
    "                        formation[onglet_name][\"Exemples de formations poursuivies\"].append(element.get_text())\n",
    "                    if element.name=='p' and element.get_text() not in [\"Poursuite d'études conditionnelle\"]:\n",
    "                        formation[onglet_name][\"Poursuivre\"].append(element.get_text().strip())\n",
    "                        \n",
    "        return formation\n",
    "    \n",
    "    except:\n",
    "        return('error')\n",
    "\n",
    "#formation = parse_formation_page(\"http://www.onisep.fr/Ressources/Univers-Formation/Formations/Post-bac/BTS-Maintenance-des-systemes-electro-navals\")\n",
    "#formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_name_formation(link):\n",
    "    try:\n",
    "        page = request.urlopen(link).read().decode('utf-8')\n",
    "\n",
    "        page = page.replace('€', 'euros')  # because encode/decode error\n",
    "        page = page.replace(u\"\\u2019\", \"'\")  # because encode/decode error\n",
    "        page = page.replace(u\"\\u2026\", \"é\")  # because encode/decode error\n",
    "        page = page.replace(u\"\\u0153\", \"oe\")  # because encode/decode error\n",
    "\n",
    "        page = page.replace('\\n', '')  # remove new line\n",
    "        page = page.replace('  ', '')  # remove big spaces (to be more human readable)\n",
    "        #file = os.path.join(fiches_dir_path, name.replace('/', '-').replace(' ', '_') + '.html')\n",
    "        #with open(file, 'w', encoding='utf8') as f:\n",
    "        #    f.write(page)\n",
    "\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        \n",
    "        bloc = soup.find(name='h1')\n",
    "        return(bloc.get_text())\n",
    "\n",
    "    except:\n",
    "        return('error')\n",
    "        \n",
    "#name = get_name_formation('http://www.onisep.fr/Ressources/Univers-Formation/Formations/Post-bac/BTS-Management-des-unites-commerciales')\n",
    "#name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fonction pour récupérer les formations des lignes i à j dans le document formations.csv de l'Onisep\n",
    "# La liste \"errors\" contient les formations avec des liens inexistants\n",
    "def get_formations(i,j):\n",
    "    formations_links_i_j = formations_links.iloc[i:j,:]\n",
    "    formations = {}\n",
    "    errors = []\n",
    "    for row in formations_links_i_j.iterrows():\n",
    "        #name = row[1][\"libellé principal\"]\n",
    "        #if str(row[1][\"libellé complémentaire\"])!='nan':\n",
    "        #    name = name + ' : ' + str(row[1][\"libellé complémentaire\"])\n",
    "        link = row[1][\"lien site onisep.fr\"]\n",
    "        name = get_name_formation(link)\n",
    "        formation_content = parse_formation_page(link)\n",
    "        if formation_content is not 'error':\n",
    "            formations[name] = formation_content\n",
    "        else:\n",
    "            name = row[1][\"libellé principal\"]\n",
    "            if str(row[1][\"libellé complémentaire\"])!='nan':\n",
    "                name = name + ' : ' + str(row[1][\"libellé complémentaire\"])\n",
    "            errors.append(name)\n",
    "                \n",
    "    # Copie du dictionnaire au format JSON\n",
    "    formations_output_path = os.path.join(dir_path, 'output/formations_' + str(i) + '_' + str(j) + '.json')\n",
    "    with open(formations_output_path, 'w') as f:\n",
    "        json.dump(formations, f, indent=4)\n",
    "\n",
    "    # Copie du dictionnaire au format JSON\n",
    "    errors_output_path = os.path.join(dir_path, 'output/errors_' + str(i) + '_' + str(j) + '.json')\n",
    "    with open(errors_output_path, 'w') as f:\n",
    "        json.dump(errors, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_formations(25,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_formations(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_formations(1000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_formations(2000,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_formations(3000,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_formations(4000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_formations(5000,6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_formations(6000,7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_formations(7000,8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_formations(8000,8096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708\n",
      "1118 410\n",
      "1357 239\n",
      "1537 180\n",
      "1734 197\n",
      "1899 165\n",
      "2070 171\n",
      "2392 322\n",
      "2404 12\n"
     ]
    }
   ],
   "source": [
    "file1 = os.path.join(dir_path,'output/formations_' + str(0) + '_' + str(1000) + '.json') \n",
    "file2 = os.path.join(dir_path,'output/formations_' + str(1000) + '_' + str(2000) + '.json') \n",
    "file3 = os.path.join(dir_path,'output/formations_' + str(2000) + '_' + str(3000) + '.json') \n",
    "file4 = os.path.join(dir_path,'output/formations_' + str(3000) + '_' + str(4000) + '.json') \n",
    "file5 = os.path.join(dir_path,'output/formations_' + str(4000) + '_' + str(5000) + '.json') \n",
    "file6 = os.path.join(dir_path,'output/formations_' + str(5000) + '_' + str(6000) + '.json') \n",
    "file7 = os.path.join(dir_path,'output/formations_' + str(6000) + '_' + str(7000) + '.json') \n",
    "file8 = os.path.join(dir_path,'output/formations_' + str(7000) + '_' + str(8000) + '.json') \n",
    "file9 = os.path.join(dir_path,'output/formations_' + str(8000) + '_' + str(8096) + '.json') \n",
    "\n",
    "\n",
    "with open(file1, 'r') as f:\n",
    "    f1 = json.load(f)\n",
    "\n",
    "with open(file2, 'r') as f:\n",
    "    f2 = json.load(f)\n",
    "\n",
    "with open(file3, 'r') as f:\n",
    "    f3 = json.load(f)\n",
    "\n",
    "with open(file4, 'r') as f:\n",
    "    f4 = json.load(f)\n",
    "    \n",
    "with open(file5, 'r') as f:\n",
    "    f5 = json.load(f)\n",
    "    \n",
    "with open(file6, 'r') as f:\n",
    "    f6 = json.load(f)\n",
    "    \n",
    "with open(file7, 'r') as f:\n",
    "    f7 = json.load(f)\n",
    "    \n",
    "with open(file8, 'r') as f:\n",
    "    f8 = json.load(f)\n",
    "\n",
    "with open(file9, 'r') as f:\n",
    "    f9 = json.load(f)\n",
    "print(len(f1))\n",
    "formations = dict(f1, **f2)\n",
    "print(len(formations), len(f2))\n",
    "formations = dict(formations, **f3)\n",
    "print(len(formations), len(f3))\n",
    "formations = dict(formations, **f4)\n",
    "print(len(formations), len(f4))\n",
    "formations = dict(formations, **f5)\n",
    "print(len(formations), len(f5))\n",
    "formations = dict(formations, **f6)\n",
    "print(len(formations), len(f6))\n",
    "formations = dict(formations, **f7)\n",
    "print(len(formations), len(f7))\n",
    "formations = dict(formations, **f8)\n",
    "print(len(formations), len(f8))\n",
    "formations = dict(formations, **f9)\n",
    "print(len(formations), len(f9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file1 = os.path.join(dir_path,'output/errors_' + str(0) + '_' + str(1000) + '.json') \n",
    "file2 = os.path.join(dir_path,'output/errors_' + str(1000) + '_' + str(2000) + '.json') \n",
    "file3 = os.path.join(dir_path,'output/errors_' + str(2000) + '_' + str(3000) + '.json') \n",
    "file4 = os.path.join(dir_path,'output/errors_' + str(3000) + '_' + str(4000) + '.json') \n",
    "file5 = os.path.join(dir_path,'output/errors_' + str(4000) + '_' + str(5000) + '.json') \n",
    "file6 = os.path.join(dir_path,'output/errors_' + str(5000) + '_' + str(6000) + '.json') \n",
    "file7 = os.path.join(dir_path,'output/errors_' + str(6000) + '_' + str(7000) + '.json') \n",
    "file8 = os.path.join(dir_path,'output/errors_' + str(7000) + '_' + str(8000) + '.json') \n",
    "file9 = os.path.join(dir_path,'output/errors_' + str(8000) + '_' + str(8096) + '.json') \n",
    "\n",
    "\n",
    "with open(file1, 'r') as f:\n",
    "    f1 = json.load(f)\n",
    "\n",
    "with open(file2, 'r') as f:\n",
    "    f2 = json.load(f)\n",
    "\n",
    "with open(file3, 'r') as f:\n",
    "    f3 = json.load(f)\n",
    "\n",
    "with open(file4, 'r') as f:\n",
    "    f4 = json.load(f)\n",
    "    \n",
    "with open(file5, 'r') as f:\n",
    "    f5 = json.load(f)\n",
    "    \n",
    "with open(file6, 'r') as f:\n",
    "    f6 = json.load(f)\n",
    "    \n",
    "with open(file7, 'r') as f:\n",
    "    f7 = json.load(f)\n",
    "    \n",
    "with open(file8, 'r') as f:\n",
    "    f8 = json.load(f)\n",
    "\n",
    "with open(file9, 'r') as f:\n",
    "    f9 = json.load(f)\n",
    "    \n",
    "errors = f1 + f2 + f3 + f4 + f5 +f6 + f7 + f8 + f9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dossier output contenant les données et les fiches\n",
    "formations_output_path = os.path.join(dir_path, 'formations.json')\n",
    "errors_output_path = os.path.join(dir_path, 'errors.json')\n",
    "\n",
    "# Copie du dictionnaire au format JSON\n",
    "with open(formations_output_path, 'w') as f:\n",
    "    json.dump(formations, f, indent=4)\n",
    "\n",
    "# Copie du dictionnaire au format JSON\n",
    "with open(errors_output_path, 'w') as f:\n",
    "    json.dump(errors, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'formations_links' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e8a4ec9f617d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mformations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformations_links\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"libellé principal\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlink\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lien site onisep.fr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'formations_links' is not defined"
     ]
    }
   ],
   "source": [
    "# Boucle pour récupérer les formations\n",
    "# La liste \"errors\" contient les formations avec des liens inexistants\n",
    "\n",
    "#formations = {}\n",
    "#errors = []\n",
    "#for row in formations_links.iterrows():\n",
    "#    name = row[1][\"libellé principal\"]\n",
    "#    link = row[1][\"lien site onisep.fr\"]\n",
    "#    formation_content = parse_formation_page(link)\n",
    "#    if formation_content is not 'error':\n",
    "#        formations[name] = formation_content\n",
    "#    else:\n",
    "#        errors.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
