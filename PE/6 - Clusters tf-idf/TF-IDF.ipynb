{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readme "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ce script permet de faire un tf-idf d'un texte par rapport à un ensemble de textes.\n",
    "\n",
    "Prérequis : un fichier 'data.json' qui contient l'ensemble de tous les textes, importé dans le format d'un dictionnaire les keys sont les titres des textes (par exemple les noms des métiers ou code ROME) les valeurs des keys les textes.\n",
    "\n",
    "Un fichier 'tf_idf.json' sera créer dans un dossier output. Ce fichier contient une liste de mots pour chacune des keys de 'data.json'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions utiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from nltk import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonction pour nettoyer le texte des caractères spéciaux\n",
    "def clean_text(text, characters):\n",
    "    c_text = text\n",
    "    for char in characters:\n",
    "        c_text = c_text.replace(char, \" \")\n",
    "    c_text = c_text.lower()\n",
    "    return(c_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calcul de document frequency\n",
    "def df(data):\n",
    "    df = {}\n",
    "    for desc in data.values():\n",
    "        for token in set(word_tokenize(desc)):\n",
    "            stem = stemmer.stem(token)\n",
    "            if stem in df:\n",
    "                df[stem] += 1\n",
    "            else:\n",
    "                df[stem] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Récupération des mots stemmés\n",
    "def stem_words(data):\n",
    "    stem_dict = {}\n",
    "    for k, desc in data.items():\n",
    "        tokens = word_tokenize(desc)\n",
    "        for t in tokens:\n",
    "            token_stem = stemmer.stem(t)\n",
    "            if token_stem in stem_dict:\n",
    "                stem_dict[token_stem].append(t)\n",
    "            else:\n",
    "                stem_dict[token_stem] = [t]\n",
    "\n",
    "    for k, v in stem_dict.items():\n",
    "        stem_dict[k] = list(set(stem_dict[k]))\n",
    "    \n",
    "    return stem_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tri des mots par leur valeur de tf-idf.\n",
    "def sorted_tfidf(tf_idf, stem_dict, nb_mots=15):\n",
    "    sorted_tfidf = {}\n",
    "    for clus, dico in tf_idf.items():\n",
    "        list_temp = [(j, i) for i, j in dico.items()]  # on met la valeur du tfidf du mot en 1er attribut\n",
    "        list_temp = sorted(list_temp, reverse=True)  # on ordonne la liste suivant les valeurs de tfidf décroissante\n",
    "        tfidf_clus = [(j,i) for i, j in list_temp]\n",
    "        sorted_clus = []\n",
    "        for (token, j) in tfidf_clus:\n",
    "            token = stem_dict[token]\n",
    "            sorted_clus.append([token, j])\n",
    "        sorted_tfidf[clus] = sorted_clus[0:nb_mots]\n",
    "        \n",
    "    final_tfidf = {}\n",
    "    for k, v in sorted_tfidf.items():\n",
    "        final_tfidf[k] = []\n",
    "        for item in v:\n",
    "            final_tfidf[k].append(item[0][0])\n",
    "    return final_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf-idf for all texts\n",
    "def tf_idf(data, nb_mots):\n",
    "    nb_texts = len(data.keys())\n",
    "    term_freq = df(data)\n",
    "\n",
    "    tf_idf ={}\n",
    "    for k, desc in data.items():\n",
    "        tf_idf_clus = {}\n",
    "        tokens = word_tokenize(desc)\n",
    "        tokens = [stemmer.stem(t) for t in tokens]\n",
    "        frequencies = FreqDist(tokens)\n",
    "\n",
    "        for token, freq in frequencies.items():\n",
    "            tf_idf_clus[token] = freq * math.log( nb_texts / (1 + term_freq.get(token, 0)) )\n",
    "\n",
    "        tf_idf[k] = tf_idf_clus\n",
    "\n",
    "    stem_dict = stem_words(data)\n",
    "    return sorted_tfidf(tf_idf,stem_dict,nb_mots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Préparation des chemins utiles et chargement des données\n",
    "\n",
    "# Prend le chemin du working directory\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "# Ensemble des textes\n",
    "data_dir_path = os.path.join(dir_path, 'data.json')\n",
    "with open(data_dir_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Créer si besoin un dossier output et prépare le chemin pour 'tf_idf.json'\n",
    "output_dir_path = os.path.join(dir_path, 'output.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stemmer\n",
    "stemmer = SnowballStemmer('french')\n",
    "\n",
    "# Choix du nombre de mots pour le texte\n",
    "nb_mots = 15\n",
    "\n",
    "# Charactères à retirer\n",
    "special_chars = [\",\", \"\\n\",\".\", \"'\", \";\", \"\\\\n\",'\"',\")\",\"(\",\"»\",\"«\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nettoyage de la ponctuation dans les définitions des métiers\n",
    "clean_data = {}\n",
    "for k, desc in data.items():\n",
    "    desc_str = str(desc)\n",
    "    desc_c = clean_text(desc_str, special_chars)\n",
    "    clean_data[k]=desc_c\n",
    "data = clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TF-IDF et sélection des meilleurs résultats\n",
    "tf_idf = tf_idf(data, nb_mots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichages des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Afficher les résultats de tous les texts\n",
    "#print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['forestière', 'agricoles', 'engins', 'coopérative', 'r']\n"
     ]
    }
   ],
   "source": [
    "# Afficher les résultats d'un text en particulier\n",
    "key = \"A1101\"\n",
    "print(tf_idf[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copie du dictionnaire au format JSON\n",
    "with open(output_dir_path, 'w') as f:\n",
    "    json.dump(tf_idf, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
